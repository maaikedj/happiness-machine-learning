{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the UN's World Happiness Index with machine learning\n",
    "\n",
    "Maaike de Jong  \n",
    "June 2020  \n",
    "  \n",
    "See the repository's [README](https://github.com/maaikedj/happiness-machine-learning/blob/master/README.md) file for background and details on the analysis and data.  \n",
    "\n",
    "### Notebook 3: Supervised learning: linear regression\n",
    "In this notebook I perform a linear regression analysis with scikit-learn, optimising the model with recursive feature elimination. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "df = pd.read_csv('dfML_clean.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import df with several log transformed variables\n",
    "df_log = pd.read_csv('dfML_clean_tr.csv')\n",
    "df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correlations between variables with heatmap\n",
    "\n",
    "corr = df.corr()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression  \n",
    "\n",
    "* Build a model with 80% train, 20 % test data\n",
    "* Calculate train and test R2 scores\n",
    "* Average R2 scores over 1000 model runs\n",
    "\n",
    "In the visual exploration of the variables in the previous notebook we saw that some of the features are quite heavily skewed/ not normally distributed. I'll run the model with the original clean data set as well as with the dataset with several variables log transformed, to compare which performs better. \n",
    "\n",
    "There were also some variables with clear outliers. Scikit-learn's RobustScaler is a suitable scaler for dealing with outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to run a linear regression model with 1000 cycles and calculate mean R2 socres for the test and train set\n",
    "\n",
    "def linear_regression(df, test_size):\n",
    "    \n",
    "    score_list = []\n",
    "\n",
    "    for i in range(1000):\n",
    "        y = df['Happiness score']\n",
    "        X = df.drop(['Happiness score'], axis=1)\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "        LM = linear_model.LinearRegression()\n",
    "    \n",
    "        LM.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = LM.predict(X_train)\n",
    "        r2score_train = r2_score(y_train, y_pred)\n",
    "    \n",
    "        y_test_pred = LM.predict(X_test)\n",
    "        r2score_test = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "        score_list.append((r2score_train, r2score_test))\n",
    "    \n",
    "    score_df = pd.DataFrame(score_list, columns=('r2score_train', 'r2score_test'))\n",
    "    \n",
    "    return print(score_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with untransformed data\n",
    "\n",
    "linear_regression(df, 0.20)\n",
    "\n",
    "# The unscaled data performs pretty well, although there is an indication of overfitting, which is not surprising with so many variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with log transformed data\n",
    "\n",
    "linear_regression(df_log, 0.20)\n",
    "\n",
    "# The log transformed data clearly performs better than the untransformed data. The mean R2 test score is higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now with the data scaled with RobustScaler\n",
    "\n",
    "scaler = RobustScaler() \n",
    "\n",
    "scaled = scaler.fit_transform(df_log)\n",
    "df_Rscaled = pd.DataFrame(scaled)    \n",
    "\n",
    "df_Rscaled.columns = list(df_log.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with log transformed Robustscaled data\n",
    "\n",
    "linear_regression(df_Rscaled, 0.20)\n",
    "\n",
    "# This performs the same as the unscaled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive feature elimination\n",
    "\n",
    "Determine order of importance of features and eliminate one by one to check effect on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a model instance with the log transformed robust scaled data\n",
    "\n",
    "score_list = []\n",
    "\n",
    "y = df_Rscaled['Happiness score']\n",
    "X = df_Rscaled.drop(['Happiness score'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "    \n",
    "LM = linear_model.LinearRegression()\n",
    "    \n",
    "LM.fit(X_train, y_train)\n",
    "    \n",
    "y_pred = LM.predict(X_train)\n",
    "r2score_train = r2_score(y_train, y_pred)\n",
    "    \n",
    "y_test_pred = LM.predict(X_test)\n",
    "r2score_test = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "print('r2 score train = ' + str(r2score_train))\n",
    "print('r2 score test = ' + str(r2score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine order of feature importance\n",
    "\n",
    "selector = RFE(LM, n_features_to_select=1, step=1)\n",
    "\n",
    "selector = selector.fit(X, y)\n",
    "\n",
    "selector.ranking_\n",
    "\n",
    "# remains the same with different runs of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables in order of importance\n",
    "\n",
    "['GDP per capita (log)', 'Life expectancy', 'Refugees % (log)', 'Renewable energy %','Drinking water services (log)',\n",
    "'Population growth', 'Air pollution (log)', 'Internet use (% of population)', 'CO2 emission per capita (log)',\n",
    "'Land area (log)', 'Women in parliament %', 'Compulsory education (years)', 'Protected land %', 'GDP growth (annual %)',\n",
    "'Population density (log)','Gender parity index (GPI) (log)', 'Urban population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the Rscaled df to use for RFE\n",
    "\n",
    "df_RFE = df_Rscaled.copy()\n",
    "df_RFE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write new variation of model function returning a df with the number of features in the model and the R2 train and test scores:\n",
    "\n",
    "def lin_reg(df, test_size):\n",
    "    \n",
    "    score_list = []\n",
    "\n",
    "    for i in range(1000):\n",
    "        y = df['Happiness score']\n",
    "        X = df.drop(['Happiness score'], axis=1)\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "        LM = linear_model.LinearRegression()\n",
    "    \n",
    "        LM.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = LM.predict(X_train)\n",
    "        r2score_train = r2_score(y_train, y_pred)\n",
    "    \n",
    "        y_test_pred = LM.predict(X_test)\n",
    "        r2score_test = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "        score_list.append((len(X.columns), r2score_train, r2score_test))\n",
    "    \n",
    "    score_df = pd.DataFrame(score_list, columns=('nr_vars', 'R2score_train', 'R2score_test'))\n",
    "    score_mean = pd.DataFrame(score_df.mean()).transpose()\n",
    "    \n",
    "    return score_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create reverse list of variables to remove one by one from original df\n",
    "\n",
    "varlist = ['Life expectancy', 'Refugees % (log)', 'Renewable energy %','Drinking water services (log)',\n",
    "'Population growth', 'Air pollution (log)', 'Internet use (% of population)', 'CO2 emission per capita (log)',\n",
    "'Land area (log)', 'Women in parliament %', 'Compulsory education (years)', 'Protected land %', 'GDP growth (annual %)',\n",
    "'Population density (log)','Gender parity index (GPI) (log)', 'Urban population']\n",
    "\n",
    "varlist.reverse()\n",
    "\n",
    "varlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty df with RFE results\n",
    "\n",
    "RFE_results = pd.DataFrame(columns=['nr_vars', 'R2score_train', 'R2score_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through varlist to drop vars from model one by one\n",
    "# run model 1000x each time and add mean R2 train and test scores to RFE results df\n",
    "# This cell can take while to run!\n",
    "\n",
    "for col in varlist:\n",
    "    \n",
    "    df_RFE.drop([col], axis=1, inplace = True)\n",
    "\n",
    "    RFE_results = pd.concat([RFE_results, lin_reg(df_RFE, 0.20)], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFE_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat df for plotting\n",
    "\n",
    "RFE_melt = pd.melt(RFE_results, id_vars = ['nr_vars'], value_vars = ['R2score_train', 'R2score_test'])\n",
    "RFE_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot train and test scores of the RFE reduced models to check the progression of the scores over the number of variables\n",
    "\n",
    "sns.set()\n",
    "sns.set_style('white')\n",
    "sns.set_color_codes('pastel')\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "sns.lineplot(x = 'nr_vars', y = 'value', hue = 'variable', palette = 'Set2', data = RFE_melt, linewidth=2)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=16) \n",
    "ax.tick_params(axis='both', which='minor', labelsize=16)\n",
    "ax.set_xticks(range(0, 17, 2))\n",
    "\n",
    "ax.legend(loc=\"lower right\", frameon=True, fontsize = 12)\n",
    "\n",
    "plt.xlabel('Number of variables', fontsize=16)\n",
    "plt.ylabel('R2 score', fontsize=16)\n",
    "plt.suptitle('R2 train and test scores recursive feature elimination', fontsize=20)\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the figure it looks like the model performs best with only the top three variables:\n",
    "# 'GDP per capita (log)', 'Life expectancy', 'Refugees % (log)'\n",
    "# When more variables are added the R2 test score doesn't go up anymore, while the R2 train score does go up, indicating overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare fit of top 6 variables in a plot\n",
    "# Indeed the top three show the best regression fit\n",
    "\n",
    "x = df_log['Happiness score']\n",
    "\n",
    "f, axes = plt.subplots(3, 3, figsize=(16, 12), sharex=True)\n",
    "sns.regplot(x = x, y = df_log['GDP per capita (log)'], ax=axes[0, 0])\n",
    "sns.regplot(x = x, y = df_log['Life expectancy'], ax=axes[0, 1])\n",
    "sns.regplot(x = x, y = df_log['Refugees % (log)'], ax=axes[0, 2])\n",
    "sns.regplot(x = x, y = df_log['Renewable energy %'], ax=axes[1, 0])\n",
    "sns.regplot(x = x, y = df_log['Drinking water services (log)'], ax=axes[1, 1])\n",
    "sns.regplot(x = x, y = df_log['Population growth'], ax=axes[1, 2])\n",
    "sns.regplot(x = x, y = df_log['Air pollution (log)'], ax=axes[2, 0])\n",
    "sns.regplot(x = x, y = df_log['Internet use (% of population)'], ax=axes[2, 1])\n",
    "sns.regplot(x = x, y = df_log['CO2 emission per capita (log)'], ax=axes[2, 2])\n",
    "\n",
    "plt.suptitle('Regression of top 6 variables with Happiness score', fontsize=24)\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
